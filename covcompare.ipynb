{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-24T23:31:29.226821Z",
     "start_time": "2025-04-24T23:30:57.204522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.516737822895553\n",
      "28.005545215042776\n",
      "Total lines missed 45\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  File  Num lines missed  \\\n4    out/Debug/gen/node/src/dawn/node/interop/WebGP...                14   \n89                   src/dawn/native/CommandBuffer.cpp                 4   \n102                src/dawn/native/EncodingContext.cpp                 5   \n122                     src/dawn/native/ObjectBase.cpp                 3   \n150                        src/dawn/native/Texture.cpp                 5   \n187                      src/dawn/node/binding/GPU.cpp                 2   \n188               src/dawn/node/binding/GPUAdapter.cpp                 3   \n202                src/dawn/node/binding/GPUDevice.cpp                 5   \n205                 src/dawn/node/binding/GPUQueue.cpp                 1   \n365  src/tint/lang/wgsl/ast/transform/promote_side_...                 3   \n\n                                          Lines missed  \n4    [872, 1912, 1913, 1916, 2831, 2899, 2900, 2901...  \n89                                    [72, 73, 74, 75]  \n102                          [175, 177, 178, 179, 180]  \n122                                    [127, 128, 129]  \n150                       [864, 865, 1331, 1332, 1333]  \n187                                         [272, 273]  \n188                                    [129, 130, 131]  \n202                          [160, 161, 162, 163, 164]  \n205                                              [157]  \n365                                    [159, 160, 161]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Num lines missed</th>\n      <th>Lines missed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>out/Debug/gen/node/src/dawn/node/interop/WebGP...</td>\n      <td>14</td>\n      <td>[872, 1912, 1913, 1916, 2831, 2899, 2900, 2901...</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>src/dawn/native/CommandBuffer.cpp</td>\n      <td>4</td>\n      <td>[72, 73, 74, 75]</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>src/dawn/native/EncodingContext.cpp</td>\n      <td>5</td>\n      <td>[175, 177, 178, 179, 180]</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>src/dawn/native/ObjectBase.cpp</td>\n      <td>3</td>\n      <td>[127, 128, 129]</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>src/dawn/native/Texture.cpp</td>\n      <td>5</td>\n      <td>[864, 865, 1331, 1332, 1333]</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>src/dawn/node/binding/GPU.cpp</td>\n      <td>2</td>\n      <td>[272, 273]</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>src/dawn/node/binding/GPUAdapter.cpp</td>\n      <td>3</td>\n      <td>[129, 130, 131]</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>src/dawn/node/binding/GPUDevice.cpp</td>\n      <td>5</td>\n      <td>[160, 161, 162, 163, 164]</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>src/dawn/node/binding/GPUQueue.cpp</td>\n      <td>1</td>\n      <td>[157]</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>src/tint/lang/wgsl/ast/transform/promote_side_...</td>\n      <td>3</td>\n      <td>[159, 160, 161]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dict_from_file(file_path):\n",
    "    \"\"\" Load JSON dictionary from a file. \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)['f']\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found.\")\n",
    "        sys.exit(1)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "def parse_non_covered_lines(coverage_dict):\n",
    "    all_non_covered_lines = {}\n",
    "    total_covered = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for file, coverage_data in coverage_dict.items():\n",
    "        # Parse percentage (already a decimal)\n",
    "        p = coverage_data['p']\n",
    "        file_coverage_info = {'percentage': p}\n",
    "\n",
    "        # Flatten uncovered line ranges\n",
    "        non_covered_lines = set()\n",
    "        raw_non_covered_lines = coverage_data['u']\n",
    "\n",
    "        for entry in raw_non_covered_lines:\n",
    "            start_line = entry[0]\n",
    "            end_line = entry[2]\n",
    "            non_covered_lines.update(range(start_line, end_line + 1))\n",
    "\n",
    "        uncovered_count = len(non_covered_lines)\n",
    "\n",
    "        # Estimate total and covered lines\n",
    "        if p < 1.0:\n",
    "            estimated_total_lines = int(uncovered_count / (1 - p))\n",
    "        else:\n",
    "            estimated_total_lines = uncovered_count  # No uncovered lines → total = uncovered_count (0)\n",
    "\n",
    "        covered_count = estimated_total_lines - uncovered_count\n",
    "\n",
    "        # Add to global totals\n",
    "        total_covered += covered_count\n",
    "        total_lines += estimated_total_lines\n",
    "\n",
    "        file_coverage_info['non_covered_lines'] = non_covered_lines\n",
    "        file_coverage_info['uncovered_count'] = uncovered_count\n",
    "        file_coverage_info['total_lines_count'] = estimated_total_lines\n",
    "        all_non_covered_lines[file] = file_coverage_info\n",
    "\n",
    "    return all_non_covered_lines, total_covered\n",
    "\n",
    "\n",
    "def compare_coverage(fuzzer_non_covered_lines, cts_non_covered_lines):\n",
    "    coverage_diff = {}\n",
    "\n",
    "    for file, coverage_data in fuzzer_non_covered_lines.items():\n",
    "        fuzzer_percent_coverage = coverage_data['percentage']\n",
    "\n",
    "        if file not in cts_non_covered_lines:\n",
    "            lines_not_covered_by_cts = set()\n",
    "        else:\n",
    "            lines_not_covered_by_cts = cts_non_covered_lines[file]['non_covered_lines']\n",
    "            \n",
    "        file_coverage_info = {}\n",
    "\n",
    "        lines_not_covered_by_fuzzer = coverage_data['non_covered_lines']\n",
    "\n",
    "        lines_covered_by_fuzzer_but_not_cts = lines_not_covered_by_cts.difference(lines_not_covered_by_fuzzer)\n",
    "\n",
    "        file_coverage_info['num_lines_missed'] = len(lines_covered_by_fuzzer_but_not_cts)\n",
    "        file_coverage_info['lines_missed'] = sorted(lines_covered_by_fuzzer_but_not_cts)\n",
    "        coverage_diff[file] = file_coverage_info\n",
    "\n",
    "    # Add all CTS files\n",
    "    for file, coverage_data in cts_non_covered_lines.items():\n",
    "        if file in coverage_diff:\n",
    "            continue\n",
    "        \n",
    "        file_coverage_info = {'num_lines_missed': 0, 'lines_missed': set()}\n",
    "        coverage_diff[file] = file_coverage_info\n",
    "    return coverage_diff\n",
    "\n",
    "\n",
    "def display_difference(difference_in_coverage):\n",
    "    # Create a list of tuples from the dictionary, selecting both 'percentage' and 'difference' values\n",
    "    data = [(file, info['num_lines_missed'], info['lines_missed']) for file, info in difference_in_coverage.items()]\n",
    "\n",
    "    # Create DataFrame with appropriate column names\n",
    "    df = pd.DataFrame(data, columns=['File', 'Num lines missed', 'Lines missed'])\n",
    "    \n",
    "    filtered_df = df[df['Num lines missed'] > 0]\n",
    "\n",
    "    # Sort the DataFrame by the 'File' column\n",
    "    print(\"Total lines missed\", df['Num lines missed'].sum())\n",
    "    return filtered_df.sort_values(by='File')\n",
    "\n",
    "\n",
    "def collate_coverage(dict_to_collate_to, dict_to_collate_from):\n",
    "    total_covered = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for file, coverage_data in dict_to_collate_from.items():\n",
    "        if file not in dict_to_collate_to:\n",
    "            # Just copy the full file entry over\n",
    "            dict_to_collate_to[file] = coverage_data\n",
    "            total_covered += coverage_data['total_lines_count'] - coverage_data['uncovered_count']\n",
    "            total_lines += coverage_data['total_lines_count']\n",
    "            continue\n",
    "\n",
    "        # File exists in both — merge uncovered lines\n",
    "        existing_data = dict_to_collate_to[file]\n",
    "        merged_non_covered = existing_data['non_covered_lines'].intersection(\n",
    "            coverage_data['non_covered_lines']\n",
    "        )\n",
    "\n",
    "        uncovered_count = len(merged_non_covered)\n",
    "        estimated_total_lines = existing_data['total_lines_count']  # use the existing estimate\n",
    "        covered_count = estimated_total_lines - uncovered_count\n",
    "\n",
    "        # Update file entry\n",
    "        dict_to_collate_to[file] = {\n",
    "            'non_covered_lines': merged_non_covered,\n",
    "            'uncovered_count': uncovered_count,\n",
    "            'total_lines_count': estimated_total_lines\n",
    "        }\n",
    "\n",
    "        # Update global totals\n",
    "        total_covered += covered_count\n",
    "        total_lines += estimated_total_lines\n",
    "\n",
    "    return dict_to_collate_to, total_covered, total_lines\n",
    "\n",
    "\n",
    "def cov_compare(fuzzer_cov_path, cts_cov_path):\n",
    "    # Get coverage stats from JSON\n",
    "    fuzzer_coverage_dict = load_dict_from_file(fuzzer_cov_path)\n",
    "    cts_coverage_dict = load_dict_from_file(cts_cov_path)\n",
    "    cts_shader_coverage_dict = load_dict_from_file(cts_shader_coverage_path)\n",
    "\n",
    "    # Parse all covered lines by file\n",
    "    fuzzer_non_covered_lines, fuzzer_total_covered_lines = parse_non_covered_lines(fuzzer_coverage_dict)\n",
    "    cts_non_covered_lines, _ = parse_non_covered_lines(cts_coverage_dict)\n",
    "    cts_shader_non_covered_lines, _ = parse_non_covered_lines(cts_shader_coverage_dict)\n",
    "    \n",
    "\n",
    "    collated_coverage, total_covered, total_lines = collate_coverage(cts_non_covered_lines, cts_shader_non_covered_lines)\n",
    "    print((fuzzer_total_covered_lines / total_lines) * 100)\n",
    "    print((total_covered / total_lines) * 100)\n",
    "\n",
    "    # Get a dictionary of the percent covered by fuzzer but not CTS\n",
    "    difference_in_coverage = compare_coverage(fuzzer_non_covered_lines, cts_non_covered_lines)\n",
    "\n",
    "    # Print to dataframe\n",
    "    return display_difference(difference_in_coverage)\n",
    "\n",
    "\n",
    "# File paths (replace these with the actual paths to your JSON files)\n",
    "fuzzer_coverage_path = './webglitch_no_swarm_formatted.json'\n",
    "cts_coverage_path = './cts_api_formatted.json'\n",
    "cts_shader_coverage_path = './cts_shader_formatted.json'\n",
    "\n",
    "df = cov_compare(fuzzer_coverage_path, cts_coverage_path)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:45.427653Z",
     "start_time": "2024-09-05T16:40:45.425796Z"
    }
   },
   "id": "c35620ca15244259",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-05T16:40:45.429699Z",
     "start_time": "2024-09-05T16:40:45.428355Z"
    }
   },
   "id": "3fbe670b6acf5cc5",
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
